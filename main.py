import streamlit as st
from langchain.chat_models import ChatOpenAI
from notion_save import save_discussion_to_notion
from datetime import datetime
import os
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# LLMã®åˆæœŸåŒ–
llm = ChatOpenAI(temperature=0.5, model_name="gpt-4")

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("Deep Discussion AI Agent")

# å…¥åŠ›UI
with st.form("discussion_form"):
    prompt = st.text_area("Prompt", height=150, placeholder="è­°è«–ã—ãŸã„ãƒ†ãƒ¼ãƒã‚’å…¥åŠ›ï¼ˆæ”¹è¡Œå¯ï¼‰")
    submitted = st.form_submit_button("Start")

# è­°è«–ã‚¹ã‚¿ãƒ¼ãƒˆ
if submitted and prompt:
    st.write("ğŸš€ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®Ÿè¡Œä¸­...")

    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒ¼ï¼ˆé€²æ—è¡¨ç¤ºï¼‰
    step_placeholder = st.empty()
    step_placeholder.info("Step 0 / 11 é€²è¡Œä¸­...")

    # ã‚¹ãƒ†ãƒƒãƒ—å‡ºåŠ›è¡¨ç¤º
    output_placeholder = st.container()
    discussion_log = []

    # ã‚¹ãƒ†ãƒƒãƒ— 1: åˆå›ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼å¿œç­”
    step_placeholder.info("Step 1 / 11")
    system_prompt = "ã‚ãªãŸã¯Speakerã§ã™ã€‚ä»¥ä¸‹ã®ãƒ†ãƒ¼ãƒã«ã¤ã„ã¦ã‚ãªãŸã®æ¨è«–ã®é™ç•Œã¾ã§è€ƒãˆã€æ˜æ™°ã‹ã¤è«–ç†çš„ã«æ•´ç†ã—ã¦ãã ã•ã„ã€‚"
    user_prompt = f"ãƒ†ãƒ¼ãƒ: {prompt}"
    response = llm.predict(system_prompt + "\n" + user_prompt)
    output_placeholder.markdown(f"### Step 1 - Speaker\n{response}")
    discussion_log.append(f"### Step 1 - Speaker\n{response}")

    # ã‚¹ãƒ†ãƒƒãƒ— 2ã€œ10: äº¤äº’å¯¾è©±ï¼ˆSpeaker/Listenerï¼‰
    for step in range(2, 11):
        role = "Listener" if step % 2 == 0 else "Speaker"

        if role == "Speaker":
            system_prompt = (
                "ã‚ãªãŸã¯Speakerã§ã™ã€‚ä»¥ä¸‹ã®å‰ã®ç™ºè¨€ã«å¯¾ã—ã¦ã€"
                "è‡ªåˆ†ã®è€ƒãˆã‚’æ¨è«–ã®é™ç•Œã¾ã§æ˜ã‚Šä¸‹ã’ã€æ˜æ™°ã§è«–ç†çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚"
            )
            user_prompt = discussion_log[-1]
            response = llm.predict(system_prompt + "\n" + user_prompt)
            output_placeholder.markdown(f"### Step {step} - Speaker\n{response}")
            discussion_log.append(f"### Step {step} - Speaker\n{response}")

        else:
            system_prompt = (
                "ã‚ãªãŸã¯Listenerã§ã™ã€‚ä»¥ä¸‹ã®ç™ºè¨€ã«å¯¾ã—ã¦ã€ã‚ˆã‚Šæ·±ãæ˜ã‚Šä¸‹ã’ã‚‹ãŸã‚ã®è³ªå•ã‚’3ã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\n"
                "æ¬¡ã®3ã¤ã®è¦³ç‚¹ã‹ã‚‰ãã‚Œãã‚Œ1å•ãšã¤ä½œæˆã—ã¦ãã ã•ã„ï¼š\n"
                "1. Clarifyï¼ˆæ˜ç¢ºåŒ–ï¼‰\n"
                "2. Challengeï¼ˆæ‰¹åˆ¤çš„æ¤œè¨ï¼‰\n"
                "3. Connectï¼ˆä»–ã®æ–‡è„ˆã¨ã®é–¢é€£ï¼‰"
            )
            user_prompt = discussion_log[-1]
            response = llm.predict(system_prompt + "\n" + user_prompt)
            output_placeholder.markdown(f"### Step {step} - Listener\n{response}")
            discussion_log.append(f"### Step {step} - Listener\n{response}")

        step_placeholder.info(f"Step {step} / 11")

    # ã‚¹ãƒ†ãƒƒãƒ— 11: Speakerã«ã‚ˆã‚‹ã¾ã¨ã‚
    step_placeholder.info("Step 11 / 11")
    system_prompt = "ã‚ãªãŸã¯Speakerã§ã™ã€‚ã“ã‚Œã¾ã§ã®å¯¾è©±ã‚’è¸ã¾ãˆã€è«–ç‚¹ãŒæœ€ã‚‚æ·±ã¾ã£ãŸå†…å®¹ã‚’æŠ½å‡ºã—ã¦è«–ç†çš„ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚æ—¥æœ¬èªã§ã€‚"
    user_prompt = "\n".join(discussion_log)
    response = llm.predict(system_prompt + "\n" + user_prompt)
    output_placeholder.markdown(f"### Step 11 - Speaker Summary\n{response}")
    discussion_log.append(f"### Step 11 - Speaker Summary\n{response}")

    # ä¿å­˜å‡¦ç†
    title = prompt.strip().split("\n")[0][:30]
    success = save_discussion_to_notion(title=title, content="\n\n".join(discussion_log))
    if success:
        st.success("âœ… è­°è«–å†…å®¹ã‚’Notionã«ä¿å­˜ã—ã¾ã—ãŸ")
    else:
        st.error("âŒ Notionã¸ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")
